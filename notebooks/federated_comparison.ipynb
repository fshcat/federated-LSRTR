{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46f5b424",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "PROJECT_ROOT = os.path.abspath(os.path.dirname(sys.path[0]))\n",
    "sys.path.append(PROJECT_ROOT)\n",
    "\n",
    "from lsr_tensor import *\n",
    "from lsr_bcd_regression import *\n",
    "import torch\n",
    "import torch.nn.functional as f\n",
    "from datasets import *\n",
    "from federated_algos import *\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from federated_tests import *\n",
    "from medmnist import VesselMNIST3D\n",
    "import cProfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cbf4191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests\n",
    "shape, ranks, separation_rank = (16, 16, 16), (2, 2, 2), 2\n",
    "x_stdev = 1\n",
    "y_stdev = 0.05\n",
    "sample_size = 2000\n",
    "val_sample_size = int(sample_size * 0.1)\n",
    "\n",
    "with torch.no_grad():\n",
    "    true_lsr = LSR_tensor_dot(shape, ranks, separation_rank)\n",
    "    f.normalize(true_lsr.core_tensor, p=2, dim=0, out=true_lsr.core_tensor)\n",
    "    true_lsr.core_tensor *= (5 / torch.sqrt(torch.sqrt(torch.prod(torch.tensor(ranks)))))\n",
    "    \n",
    "dataset = synthesize_data(true_lsr, sample_size, shape, x_stdev, y_stdev)\n",
    "val_dataset = synthesize_data(true_lsr, val_sample_size, shape, x_stdev, y_stdev)\n",
    "client_datasets = federate_dataset(dataset, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fadda47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vessel MNIST 3D\n",
    "shape, ranks, separation_rank = (28, 28, 28), (3, 3, 3), 2\n",
    "vessel_dataset = VesselMNIST3D(split=\"train\", download=True)\n",
    "vessel_client_datasets = federate_dataset(vessel_dataset, 5)\n",
    "vessel_val_dataset = VesselMNIST3D(split=\"val\", download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ee72f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stepwise federated algorithm training...\n",
      "Run 0\n",
      "0 0\n",
      "0 1\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 51, in starmapstar\n    return list(itertools.starmap(args[0], args[1]))\n  File \"/home/fishcat/Federated-LSRTR/federated_tests.py\", line 12, in run_trial\n    _, val_loss = method(init_tensor_dot, *args)\n  File \"/home/fishcat/Federated-LSRTR/federated_algos.py\", line 98, in BCD_federated_stepwise\n    client_out = client_update_factor(init_tensor, s, k, client_dataloader, optim_fn, loss_fn, hypers[\"steps\"])\n  File \"/home/fishcat/Federated-LSRTR/federated_algos.py\", line 36, in client_update_factor\n    y_predicted = tensor.bcd_factor_forward(s, k, X)\n  File \"/home/fishcat/Federated-LSRTR/lsr_tensor.py\", line 114, in bcd_factor_forward\n    x_combined = self.bcd_factor_update_x(s, k, x) if not precombined else x\n  File \"/home/fishcat/.local/lib/python3.8/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n    return func(*args, **kwargs)\n  File \"/home/fishcat/Federated-LSRTR/lsr_tensor.py\", line 84, in bcd_factor_update_x\n    (ten.tenalg.kronecker(self.factor_matrices[s], skip_matrix=k, reverse=True) @\n  File \"/home/fishcat/.local/lib/python3.8/site-packages/tensorly/backend/__init__.py\", line 206, in wrapped_backend_method\n    return getattr(\n  File \"/home/fishcat/.local/lib/python3.8/site-packages/tensorly/tenalg/core_tenalg/_kronecker.py\", line 54, in kronecker\n    res = T.kron(res, matrix)\n  File \"/home/fishcat/.local/lib/python3.8/site-packages/tensorly/backend/__init__.py\", line 206, in wrapped_backend_method\n    return getattr(\nRuntimeError: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m lsr_dot_params \u001b[38;5;241m=\u001b[39m (shape, ranks, separation_rank, torch\u001b[38;5;241m.\u001b[39mfloat32, torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m      6\u001b[0m args \u001b[38;5;241m=\u001b[39m (BCD_federated_stepwise, lsr_dot_params, client_datasets, val_dataset,\\\n\u001b[1;32m      7\u001b[0m         hypers, loss_fn, aggregator_fn, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m----> 9\u001b[0m avg_loss, error \u001b[38;5;241m=\u001b[39m \u001b[43mrun_test\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Federated-LSRTR/federated_tests.py:24\u001b[0m, in \u001b[0;36mrun_test\u001b[0;34m(n_runs, n_workers, method, tensor_params, verbose, *args)\u001b[0m\n\u001b[1;32m     22\u001b[0m     arg_list \u001b[38;5;241m=\u001b[39m [(method, tensor_params, \u001b[38;5;241m*\u001b[39margs) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_workers)]\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m mp\u001b[38;5;241m.\u001b[39mget_context(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mPool(processes\u001b[38;5;241m=\u001b[39mn_workers) \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[0;32m---> 24\u001b[0m         results\u001b[38;5;241m.\u001b[39mextend(\u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstarmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_trial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg_list\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     26\u001b[0m results \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack(results)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(results, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m), np\u001b[38;5;241m.\u001b[39mstd(results, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3.8/multiprocessing/pool.py:372\u001b[0m, in \u001b[0;36mPool.starmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstarmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    367\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;124;03m    Like `map()` method but the elements of the `iterable` are expected to\u001b[39;00m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;124;03m    be iterables as well and will be unpacked as arguments. Hence\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;124;03m    `func` and (a, b) becomes func(a, b).\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 372\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstarmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.8/multiprocessing/pool.py:771\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n\u001b[1;32m    770\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 771\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "\u001b[0;31mRuntimeError\u001b[0m: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead."
     ]
    }
   ],
   "source": [
    "print(\"Stepwise federated algorithm training...\")\n",
    "hypers = {\"max_iter\": 10, \"batch_size\": None, \"lr\": 0.001, \"momentum\": 0.9, \"steps\": 10}\n",
    "loss_fn = f.mse_loss\n",
    "aggregator_fn = avg_aggregation\n",
    "lsr_dot_params = (shape, ranks, separation_rank, torch.float32, torch.device('cpu'))\n",
    "args = (BCD_federated_stepwise, lsr_dot_params, client_datasets, val_dataset,\\\n",
    "        hypers, loss_fn, aggregator_fn, False)\n",
    "\n",
    "avg_loss, error = run_test(1, 1, *args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de279bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Stepwise federated algorithm training...\")\n",
    "hypers = {\"max_iter\": 100, \"batch_size\": None, \"lr\": 0.001, \"momentum\": 0.9, \"steps\": 10}\n",
    "loss_fn = logistic_loss\n",
    "aggregator_fn = avg_aggregation\n",
    "lsr_dot_params = (shape, ranks, separation_rank, torch.double, torch.device('cpu'))\n",
    "args = (BCD_federated_stepwise, lsr_dot_params, vessel_client_datasets, vessel_val_dataset,\\\n",
    "        hypers, loss_fn, aggregator_fn, False)\n",
    "\n",
    "avg_loss, error = run_test(1, 1, *args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09444d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(len(avg_loss)) + 1, avg_loss, label=\"Stepwise\", color=\"#23648FFF\")\n",
    "plt.fill_between(np.arange(len(avg_loss)) + 1, avg_loss-error, avg_loss+error, color=\"#23648FFF\", edgecolor=\"none\", alpha=0.5)\n",
    "plt.legend()\n",
    "plt.xlabel(\"Iteration #\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Validation Loss over # of Iterations\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7621446",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Stepwise federated algorithm training...\")\n",
    "hypers = {\"max_iter\": 10, \"batch_size\": None, \"lr\": 0.001, \"momentum\": 0.9, \"steps\": 10}\n",
    "loss_fn = f.mse_loss\n",
    "aggregator_fn = avg_aggregation\n",
    "init_lsr_dot = LSR_tensor_dot(shape, ranks, separation_rank)\n",
    "\n",
    "_, stepwise_loss = BCD_federated_stepwise(init_lsr_dot, client_datasets, val_dataset, hypers, loss_fn, aggregator_fn, verbose=True)\n",
    "\n",
    "print(\"\\nSplit factors + core federated algorithm training...\")\n",
    "hypers = {\"max_iter\": 50, \"batch_size\": None, \"lr\": 0.001, \"momentum\": 0.9, \"steps\": 10}\n",
    "loss_fn = f.mse_loss\n",
    "aggregator_fn = avg_aggregation\n",
    "init_lsr_dot = LSR_tensor_dot(shape, ranks, separation_rank)\n",
    "\n",
    "_, full_factors_loss = BCD_federated_all_factors(init_lsr_dot, client_datasets, val_dataset, hypers, loss_fn, aggregator_fn, verbose=True, ortho_iteratively=True)\n",
    "\n",
    "print(\"\\n1 full iteration federated algorithm training...\")\n",
    "hypers = {\"max_rounds\": 50, \"max_iter\": 1, \"batch_size\": None, \"lr\": 0.001, \"momentum\": 0.9, \"steps\": 10}\n",
    "loss_fn = f.mse_loss\n",
    "aggregator_fn = avg_aggregation\n",
    "init_lsr_dot = LSR_tensor_dot(shape, ranks, separation_rank)\n",
    "\n",
    "_, full_1_iter_loss = BCD_federated_full_iteration(init_lsr_dot, client_datasets, val_dataset, hypers, loss_fn, aggregator_fn, verbose=True)\n",
    "\n",
    "print(\"\\n5 full iteration federated algorithm training...\")\n",
    "hypers = {\"max_rounds\": 10, \"max_iter\": 5, \"batch_size\": None, \"lr\": 0.001, \"momentum\": 0.9, \"steps\": 10}\n",
    "loss_fn = f.mse_loss\n",
    "aggregator_fn = avg_aggregation\n",
    "init_lsr_dot = LSR_tensor_dot(shape, ranks, separation_rank)\n",
    "\n",
    "_, full_5_iter_loss = BCD_federated_full_iteration(init_lsr_dot, client_datasets, val_dataset, hypers, loss_fn, aggregator_fn, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4deabe48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "init_lsr_dot = LSR_tensor_dot(shape, ranks, separation_rank)\n",
    "_, unfederated_diag = lsr_bcd_regression(f.mse_loss, dataset, init_lsr_dot, lr=0.001, momentum=0.9,\\\n",
    "                                        step_epochs=10, max_iter=50, batch_size=None, threshold=1e-4, init_zero=False, ortho=True,\\\n",
    "                                        verbose=True, true_param=None, val_dataset=val_dataset)\n",
    "unfederated_loss = unfederated_diag[\"val_loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55ae558",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(len(unfederated_loss)) + 1, unfederated_loss, label=\"Unfederated\")\n",
    "plt.plot(np.arange(len(stepwise_loss)) + 1, stepwise_loss, label=\"Stepwise\")\n",
    "plt.plot(np.arange(len(full_factors_loss)) + 1, full_factors_loss, label=\"Full Factors + Core\")\n",
    "plt.plot(np.arange(len(full_1_iter_loss)) + 1, full_1_iter_loss, label=\"Full 1 Iteration\")\n",
    "plt.plot((np.arange(len(full_5_iter_loss)) + 1)*5, full_5_iter_loss, label=\"Full 5 Iterations\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Iteration #\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Validation Loss over # of Iterations\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e8a4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance testing\n",
    "print(\"Stepwise federated algorithm training...\")\n",
    "hypers = {\"max_iter\": 100, \"batch_size\": None, \"lr\": 0.001, \"momentum\": 0.9, \"steps\": 10}\n",
    "loss_fn = f.mse_loss\n",
    "aggregator_fn = avg_aggregation\n",
    "lsr_dot_params = (shape, ranks, separation_rank, torch.float32, torch.device('cuda'))\n",
    "init_lsr_dot = LSR_tensor_dot(*lsr_dot_params)\n",
    "cProfile.run(\"BCD_federated_stepwise(init_lsr_dot, client_datasets, val_dataset,\\\n",
    "              hypers, loss_fn, aggregator_fn, False)\", sort='tottime')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
