{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46f5b424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please install the required packages first. Use `pip install -r requirements.txt`.\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "PROJECT_ROOT = os.path.abspath(os.path.dirname(sys.path[0]))\n",
    "sys.path.append(PROJECT_ROOT)\n",
    "\n",
    "from lsr_tensor import *\n",
    "from lsr_bcd_regression import *\n",
    "import torch\n",
    "import torch.nn.functional as f\n",
    "from datasets import *\n",
    "from federated_algos import *\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from federated_tests import *\n",
    "from medmnist import BreastMNIST, VesselMNIST3D\n",
    "import cProfile\n",
    "from torchvision import transforms\n",
    "from copy import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbf4191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synthetic Data\n",
    "shape, ranks, separation_rank = (64, 64), (8, 8), 2\n",
    "loss_fn = f.mse_loss\n",
    "\n",
    "sample_size = 2000\n",
    "val_sample_size = 500\n",
    "clients = 10\n",
    "\n",
    "synth_dataset, synth_val_dataset = synthesize_data(shape, ranks, separation_rank,\\\n",
    "                                                   sample_size, val_sample_size)\n",
    "synth_client_datasets = federate_dataset(synth_dataset, clients)\n",
    "synth_data = (synth_dataset, synth_client_datasets, synth_val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109e5406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Breast MNIST\n",
    "shape, ranks, separation_rank = (28, 28), (3, 3), 2\n",
    "loss_fn = logistic_loss\n",
    "\n",
    "transform = transforms.Compose([transforms.PILToTensor(), transforms.ConvertImageDtype(torch.float32)])\n",
    "\n",
    "breast_dataset = BreastMNIST(split=\"train\", download=True, transform=transform)\n",
    "breast_client_datasets = federate_dataset(breast_dataset, 10)\n",
    "breast_val_dataset = BreastMNIST(split=\"val\", download=True, transform=transform)\n",
    "breast_data = (breast_dataset, breast_client_datasets, breast_val_dataset)\n",
    "\n",
    "print(\"fraction positive: \", sum(breast_val_dataset[:, 0][1]) / len(breast_val_dataset[:, 0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de348213-7ec9-468f-81be-197093c9b0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vessel MNIST 3D\n",
    "vessel_dataset = VesselMNIST3D(split=\"train\", download=True)\n",
    "vessel_val_dataset = VesselMNIST3D(split=\"val\", download=True)\n",
    "vessel_client_datasets = federate_dataset(vessel_dataset, 10)\n",
    "vessel_data = (vessel_dataset, vessel_client_datasets, vessel_val_dataset)\n",
    "print([len(c) for c in vessel_client_datasets])\n",
    "print(\"fraction positive: \", sum(vessel_val_dataset[:, 0][1]) / len(vessel_val_dataset[:, 0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e44eb5-dffd-4673-8880-8085b564c5e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Tuning\n",
    "iters = 100\n",
    "n_workers = 4\n",
    "n_runs = 4\n",
    "\n",
    "path_base = \"../data/vessel_tuning\"\n",
    "dataset, client_datasets, val_dataset = vessel_data\n",
    "loss_fn = logistic_loss\n",
    "aggregator_fn = avg_aggregation\n",
    "\n",
    "shape, ranks, separation_rank = (28, 28, 28), (3, 3, 3), 2\n",
    "steps = 10\n",
    "lr = 0.001\n",
    "momentum = 0.99\n",
    "\n",
    "hypers = {\"max_rounds\": 1, \"max_iter\": iters, \"batch_size\": None, \"lr\": lr, \"momentum\": momentum, \"steps\": steps, \"threshold\": 0.0}\n",
    "lsr_dot_params = (shape, ranks, separation_rank, torch.float64, torch.device('cuda'))\n",
    "\n",
    "print(f\"Training lr {lr} steps {steps} momentum {momentum}\")\n",
    "path = f\"{path_base}/lr{int(lr*1000)}_mom{momentum}_steps{steps}\"\n",
    "args = (lsr_bcd_regression, lsr_dot_params, loss_fn, dataset, val_dataset, hypers, True)\n",
    "\n",
    "run_test(path, n_runs, n_workers, *args)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "700721bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 43\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data_fn_by_size(size)\n\u001b[1;32m     41\u001b[0m sized_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msize\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m names]\n\u001b[0;32m---> 43\u001b[0m \u001b[43mrun_combined_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_base\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_runs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_workers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlsr_dot_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msized_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethods\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg_list\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Federated-LSRTR/federated_tests.py:67\u001b[0m, in \u001b[0;36mrun_combined_test\u001b[0;34m(path, n_runs, n_trials, n_workers, data_fn, tensor_params, names, methods, arg_list, verbose, save_weights)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRun \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m mp\u001b[38;5;241m.\u001b[39mget_context(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mPool(processes\u001b[38;5;241m=\u001b[39mn_workers) \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[0;32m---> 67\u001b[0m         results\u001b[38;5;241m.\u001b[39mextend(\u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstarmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_combined_trial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial_args\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(names):\n\u001b[1;32m     70\u001b[0m     method_results \u001b[38;5;241m=\u001b[39m [rs[i] \u001b[38;5;28;01mfor\u001b[39;00m rs \u001b[38;5;129;01min\u001b[39;00m results]\n",
      "File \u001b[0;32m/usr/lib/python3.8/multiprocessing/pool.py:372\u001b[0m, in \u001b[0;36mPool.starmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstarmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    367\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;124;03m    Like `map()` method but the elements of the `iterable` are expected to\u001b[39;00m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;124;03m    be iterables as well and will be unpacked as arguments. Hence\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;124;03m    `func` and (a, b) becomes func(a, b).\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 372\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstarmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.8/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    766\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mready():\n\u001b[1;32m    767\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.8/multiprocessing/pool.py:762\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 762\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.8/threading.py:558\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    556\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    557\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 558\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/usr/lib/python3.8/threading.py:302\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 302\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    303\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Comparison of federated algos\n",
    "shape, ranks, separation_rank = (64, 64), (8, 8), 2\n",
    "lsr_dot_params = (shape, ranks, separation_rank, torch.float32, torch.device('cuda'))\n",
    "\n",
    "loss_fn = f.mse_loss\n",
    "aggregator_fn = avg_aggregation\n",
    "\n",
    "site_sizes = [100, 200, 300, 400, 500, 1000]\n",
    "iters = 200\n",
    "\n",
    "n_runs = 5\n",
    "n_trials = 8\n",
    "n_workers = 8\n",
    "\n",
    "path_base = \"../data/synth_size_test\"\n",
    "\n",
    "def data_fn_by_size(sample_size, val_sample_size=500, clients=10):\n",
    "    synth_tensor = get_synth_tensor(shape, ranks, separation_rank)\n",
    "    synth_dataset, synth_val_dataset = synthesize_data(synth_tensor, sample_size, val_sample_size)\n",
    "    synth_client_datasets = federate_dataset(synth_dataset, clients)\n",
    "    return (synth_dataset, synth_val_dataset, synth_client_datasets)\n",
    "    \n",
    "methods = [BCD_avg_local, lsr_bcd_regression, BCD_federated_stepwise, BCD_federated_all_factors, BCD_federated_full_iteration, BCD_federated_full_iteration]\n",
    "names = ['local', 'centralized', 'step', 'factors_core', 'one_iter', 'five_iter']\n",
    "\n",
    "gen_hypers = {\"max_rounds\": 1, \"max_iter\": iters, \"batch_size\": None, \"lr\": 0.001, \"momentum\": 0.9, \"steps\": 10, \"threshold\": 0.0}\n",
    "iter_hypers = {\"max_rounds\": iters, \"max_iter\": 1, \"batch_size\": None, \"lr\": 0.001, \"momentum\": 0.9, \"steps\": 10, \"threshold\": 0.0}\n",
    "iter_5_hypers = {\"max_rounds\": iters // 5, \"max_iter\": 5, \"batch_size\": None, \"lr\": 0.001, \"momentum\": 0.9, \"steps\": 10, \"threshold\": 0.0}\n",
    "\n",
    "arg_list = [(gen_hypers, loss_fn, False), # local\n",
    "            (gen_hypers, loss_fn, False), # centralized\n",
    "            (gen_hypers, loss_fn, aggregator_fn, False), # one step\n",
    "            (gen_hypers, loss_fn, aggregator_fn, False), # factors core\n",
    "            (iter_hypers, loss_fn, aggregator_fn, False), # one iter\n",
    "            (iter_5_hypers, loss_fn, aggregator_fn, False)] # five iter\n",
    "\n",
    "for size in site_sizes:\n",
    "    def data_fn():\n",
    "        return data_fn_by_size(size)\n",
    "\n",
    "    sized_names = [f\"{name}_{size}\" for name in names]\n",
    "        \n",
    "    run_combined_test(path_base, n_runs, n_trials, n_workers, data_fn, lsr_dot_params, sized_names, methods, arg_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741670f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data from runs\n",
    "path_base = \"../data/synth_size_test\"\n",
    "size = 200\n",
    "names = [f\"centralized_{size}\", f\"step_{size}\", f\"factors_core_{size}\", f\"one_iter_{size}\", f\"five_iter_{size}\", f\"local_{size}\"]\n",
    "print(names)\n",
    "#names = [f\"lr{int(lr*1000)}_mom{momentum}\" for momentum in [0.0, 0.9, 0.99] for lr in [0.1, 0.003, 0.001]]\n",
    "\n",
    "train_losses, train_std = [], []\n",
    "val_losses, val_std = [], []\n",
    "\n",
    "train_accs, train_acc_std = [], []\n",
    "val_accs, val_acc_std = [], []\n",
    "\n",
    "for name in names:\n",
    "    path = f\"{path_base}/{name}\"\n",
    "    train_losses.append(torch.mean(torch.load(f\"{path}/train_loss\"), axis=0))\n",
    "    train_std.append(torch.std(torch.load(f\"{path}/train_loss\"), axis=0))\n",
    "    \n",
    "    val_losses.append(torch.mean(torch.load(f\"{path}/val_loss\"), axis=0))\n",
    "    val_std.append(torch.std(torch.load(f\"{path}/val_loss\"), axis=0))\n",
    "\n",
    "    #train_accs.append(torch.mean(torch.load(f\"{path}/train_acc\"), axis=0))\n",
    "    #train_acc_std.append(torch.std(torch.load(f\"{path}/train_acc\"), axis=0))\n",
    "    \n",
    "    #val_accs.append(torch.mean(torch.load(f\"{path}/val_acc\"), axis=0))\n",
    "    #val_acc_std.append(torch.std(torch.load(f\"{path}/val_acc\"), axis=0))\n",
    "    \n",
    "print(\"Loaded run data\")\n",
    "print([vl.shape for vl in val_losses])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fbc72a-9886-473b-95af-3d03ec879bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data from runs (site size comparison)\n",
    "path_base = \"../data/synth_size_test\"\n",
    "\n",
    "site_sizes = [20, 100, 200, 300, 400, 500, 1000]\n",
    "\n",
    "train_losses, train_std = [], []\n",
    "val_losses, val_std = [], []\n",
    "\n",
    "names = [f\"centralized\", f\"step\", f\"factors_core\", f\"one_iter\", f\"five_iter\", f\"local\"]\n",
    "\n",
    "for name in names:\n",
    "    size_best_train, size_best_train_std = [], []\n",
    "    size_best_val, size_best_val_std = [], []\n",
    "\n",
    "    for size in site_sizes:\n",
    "        full_name = f\"{name}_{size}\"    \n",
    "        path = f\"{path_base}/{full_name}\"\n",
    "        \n",
    "        size_best_train.append(torch.mean(torch.load(f\"{path}/train_loss\").min(dim=1).values))\n",
    "        size_best_train_std.append(torch.std(torch.load(f\"{path}/train_loss\").min(dim=1).values))\n",
    "        \n",
    "        size_best_val.append(torch.mean(torch.load(f\"{path}/val_loss\").min(dim=1).values))\n",
    "        size_best_val_std.append(torch.std(torch.load(f\"{path}/val_loss\").min(dim=1).values))\n",
    "\n",
    "    train_losses.append(torch.stack(size_best_train))\n",
    "    train_std.append(torch.stack(size_best_train_std))\n",
    "    val_losses.append(torch.stack(size_best_val))\n",
    "    val_std.append(torch.stack(size_best_val_std))\n",
    "    \n",
    "print(\"Loaded run data\")\n",
    "print([vl.shape for vl in val_losses])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb42283",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\"#332288\", \"#117733\", \"#44AA99\", \"#88CCEE\", \"#DDCC77\", \"#CC6677\", \"#AA4499\", \"#882255\", \"#5D070A\"]\n",
    "labels = [\"Unfederated\", \"One step\", \"All factors, core\", \"Full iteration\", \"5 full iterations\", \"Avg Local\"]\n",
    "#labels = names\n",
    "\n",
    "xscales = [1, 1, 1, 1, 5, 1]\n",
    "#xscales = [1, 1, 1, 1, 1, 1]\n",
    "#xscales = [1, 1, 1, 1, 1, 1]\n",
    "\n",
    "metrics = val_losses\n",
    "stds = val_std\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "for metric, std, xscale, label, color in zip(metrics, stds, xscales, labels, colors):\n",
    "    plt.plot((np.arange(len(metric)) + 1)*xscale, metric, label=label, color=color, marker='o')\n",
    "    plt.fill_between((np.arange(len(metric)) + 1)*xscale, metric-std, metric+std, color=color, alpha=0.2)\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"Iteration #\", fontsize=14)\n",
    "plt.ylabel(\"Loss (Mean Squared Error)\", fontsize=14)\n",
    "plt.title(\"Model Validation Loss over Number of Iterations\\n (Synthetic Data)\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2c8104-17f0-46f7-98cb-1c5f531f9feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\"#332288\", \"#117733\", \"#44AA99\", \"#88CCEE\", \"#DDCC77\", \"#CC6677\", \"#AA4499\", \"#882255\", \"#5D070A\"]\n",
    "labels = [\"Unfederated\", \"One step\", \"All factors, core\", \"Full iteration\", \"5 full iterations\", \"Avg Local\"]\n",
    "#labels = names\n",
    "\n",
    "xscales = [1, 1, 1, 1, 1, 1]\n",
    "#xscales = [1, 1, 1, 1, 1, 1]\n",
    "#xscales = [1, 1, 1, 1, 1, 1]\n",
    "\n",
    "metrics = val_losses\n",
    "stds = val_std\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "for metric, std, xscale, label, color in zip(metrics, stds, xscales, labels, colors):\n",
    "    plt.plot([20, 100, 200, 300, 400, 500, 1000], metric, label=label, color=color, marker='o')\n",
    "    plt.fill_between([20, 100, 200, 300, 400, 500, 1000], metric-std, metric+std, color=color, alpha=0.2)\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"Amt of Data at Each Site\", fontsize=14)\n",
    "plt.ylabel(\"Loss (Mean Squared Error)\", fontsize=14)\n",
    "plt.title(\"Minimum Validation Loss over Site Sample Size\\n (Synthetic Data)\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71af6fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Testing...\")\n",
    "\n",
    "hypers = {\"max_rounds\": 1, \"max_iter\": 100, \"batch_size\": None, \"lr\": 0.001, \"momentum\": 0.9, \"steps\": 10, \"threshold\": 0.0}\n",
    "aggregator_fn = logistic_loss\n",
    "lsr_dot_params = (shape, (3, 3, 3), 2, torch.float64, torch.device('cuda'))\n",
    "\n",
    "init_lsr_dot = LSR_tensor_dot(*lsr_dot_params)\n",
    "lsr_bcd_regression(init_lsr_dot, loss_fn, vessel_dataset, vessel_val_dataset,\\\n",
    "                       hypers, True, True)\n",
    "\n",
    "print(\"Finished without errors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de758f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance testing\n",
    "print(\"Performance Testing...\")\n",
    "hypers = {\"max_rounds\": 1, \"max_iter\": 100, \"batch_size\": None, \"lr\": 0.005, \"momentum\": 0.9, \"steps\": 10, \"threshold\": 0.0}\n",
    "aggregator_fn = avg_aggregation\n",
    "lsr_dot_params = (shape, ranks, separation_rank, torch.float32, torch.device('cuda'))\n",
    "init_lsr_dot = LSR_tensor_dot(*lsr_dot_params)\n",
    "cProfile.run(\"BCD_federated_stepwise(init_lsr_dot, synth_client_datasets, synth_val_dataset,\\\n",
    "              hypers, loss_fn, aggregator_fn, False)\", sort='tottime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a44b90a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         8895036 function calls (8378207 primitive calls) in 24.134 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "    25500    3.921    0.000    3.921    0.000 {method 'run_backward' of 'torch._C._EngineBase' objects}\n",
      "    71356    2.356    0.000    2.356    0.000 {method 'to' of 'torch._C._TensorBase' objects}\n",
      "   185302    1.312    0.000    1.312    0.000 {built-in method torch.reshape}\n",
      "    60060    1.288    0.000    1.288    0.000 {built-in method torch.matmul}\n",
      "    31012    1.189    0.000    1.189    0.000 {built-in method torch._C._nn.mse_loss}\n",
      "    48450    1.181    0.000    1.181    0.000 {built-in method torch._foreach_add_}\n",
      "    22950    0.889    0.000    0.889    0.000 {built-in method torch._foreach_mul_}\n",
      "    56275    0.583    0.000    0.583    0.000 {built-in method torch._ops.profiler._record_function_enter_new}\n",
      "    22440    0.514    0.000    0.514    0.000 {built-in method torch.cat}\n",
      "    25500    0.423    0.000    0.423    0.000 {built-in method torch.ones_like}\n",
      "476764/88376    0.408    0.000    4.910    0.000 __init__.py:202(wrapped_backend_method)\n",
      "    20404    0.354    0.000    0.354    0.000 {built-in method torch.ones}\n",
      "    33052    0.341    0.000    0.341    0.000 {method 'reduce' of 'numpy.ufunc' objects}\n",
      "     7772    0.328    0.000    1.907    0.000 lsr_tensor.py:65(expand_to_tensor)\n",
      "     1772    0.294    0.000    0.294    0.000 {built-in method torch._C._linalg.linalg_qr}\n",
      "    33052    0.253    0.000    2.556    0.000 generalised_inner_product.py:8(inner)\n",
      "     1600    0.248    0.000   10.388    0.006 federated_algos.py:34(client_update_factor)\n",
      "    10458    0.244    0.000    0.244    0.000 {built-in method torch.stack}\n",
      "        5    0.238    0.048    0.431    0.086 {built-in method torch.normal}\n",
      "    25500    0.230    0.000    4.366    0.000 optimizer.py:265(wrapper)\n",
      "    56275    0.228    0.000    0.228    0.000 {built-in method torch._ops.profiler.}\n",
      "      572    0.220    0.000    5.825    0.010 federated_algos.py:107(get_full_loss)\n",
      "    67634    0.219    0.000    0.219    0.000 {built-in method torch.squeeze}\n",
      "      572    0.193    0.000    0.193    0.000 {method 'cpu' of 'torch._C._TensorBase' objects}\n",
      "    60646    0.188    0.000    0.188    0.000 {built-in method torch.moveaxis}\n",
      "    25500    0.184    0.000    0.660    0.000 optimizer.py:435(zero_grad)\n",
      "    56275    0.175    0.000    0.440    0.000 profiler.py:495(__exit__)\n",
      "   214800    0.173    0.000    0.173    0.000 dataset.py:196(<genexpr>)\n",
      "    20400    0.162    0.000    3.250    0.000 lsr_tensor.py:120(bcd_factor_forward)\n",
      "        1    0.155    0.155    0.155    0.155 {built-in method torch._C._cuda_init}\n",
      "    25500    0.154    0.000    2.731    0.000 sgd.py:268(_multi_tensor_sgd)\n",
      "       11    0.154    0.014    9.598    0.873 lsr_bcd_regression.py:6(lsr_bcd_regression)\n",
      "     1768    0.153    0.000    0.529    0.000 lsr_tensor.py:126(orthonorm_factor)\n",
      "    25500    0.146    0.000    0.225    0.000 _foreach_utils.py:20(_group_tensors_by_device_and_dtype)\n",
      "   613711    0.145    0.000    0.173    0.000 {built-in method builtins.getattr}\n",
      "     2040    0.131    0.000    0.831    0.000 lsr_tensor.py:86(bcd_factor_update_x)\n",
      "    25500    0.125    0.000    3.160    0.000 sgd.py:56(step)\n",
      "     6680    0.118    0.000    0.118    0.000 {built-in method torch.clone}\n",
      "    27008    0.114    0.000    1.205    0.000 n_mode_product.py:5(mode_dot)\n",
      "    31012    0.106    0.000    1.554    0.000 functional.py:3267(mse_loss)\n",
      "    25500    0.104    0.000    3.342    0.000 optimizer.py:29(_use_grad)\n",
      "    56275    0.101    0.000    0.219    0.000 profiler.py:482(__init__)\n",
      "    25500    0.100    0.000    4.716    0.000 _tensor.py:428(backward)\n",
      "    25500    0.099    0.000    0.117    0.000 sgd.py:37(_init_group)\n",
      "    13504    0.097    0.000    1.524    0.000 n_mode_product.py:81(multi_mode_dot)\n",
      "    31012    0.097    0.000    0.097    0.000 {built-in method torch.broadcast_tensors}\n",
      "732193/658515    0.097    0.000    0.163    0.000 {built-in method builtins.len}\n",
      "   142259    0.097    0.000    0.101    0.000 module.py:1601(__getattr__)\n",
      "    25500    0.093    0.000    4.607    0.000 __init__.py:106(backward)\n",
      "    25500    0.093    0.000    0.537    0.000 __init__.py:50(_make_grads)\n",
      "    33052    0.090    0.000    0.483    0.000 fromnumeric.py:70(_wrapreduction)\n",
      "    56275    0.089    0.000    0.707    0.000 profiler.py:491(__enter__)\n",
      "    25500    0.089    0.000    2.903    0.000 sgd.py:187(sgd)\n",
      "    31012    0.088    0.000    0.210    0.000 functional.py:45(broadcast_tensors)\n",
      "   113832    0.084    0.000    0.117    0.000 grad_mode.py:149(__init__)\n",
      "    31376    0.075    0.000    8.191    0.000 _contextlib.py:112(decorate_context)\n",
      "    60060    0.070    0.000    1.358    0.000 pytorch_backend.py:109(dot)\n",
      "     5072    0.069    0.000    0.069    0.000 {built-in method torch.eye}\n",
      "    71628    0.066    0.000    0.116    0.000 container.py:586(_get_abs_string_index)\n",
      "56276/56275    0.064    0.000    0.111    0.000 typing.py:255(inner)\n",
      "362945/341496    0.063    0.000    0.099    0.000 {built-in method builtins.isinstance}\n",
      "    66104    0.060    0.000    0.060    0.000 pytorch_backend.py:56(shape)\n",
      "      400    0.059    0.000    2.192    0.005 federated_algos.py:5(client_update_core)\n",
      "63908/61868    0.055    0.000    0.293    0.000 container.py:603(__getitem__)\n",
      "    71600    0.054    0.000    0.227    0.000 dataset.py:195(__getitem__)\n",
      "      510    0.053    0.000    0.165    0.000 lsr_tensor.py:100(bcd_core_update_x)\n",
      "    27008    0.052    0.000    0.270    0.000 base.py:56(fold)\n",
      "   568297    0.052    0.000    0.052    0.000 {method 'get' of 'dict' objects}\n",
      "    35792    0.048    0.000    0.093    0.000 container.py:281(_get_abs_string_index)\n",
      "    29048    0.046    0.000    0.282    0.000 base.py:39(unfold)\n",
      "    33052    0.045    0.000    0.528    0.000 fromnumeric.py:2881(prod)\n",
      "    31416    0.044    0.000    0.046    0.000 grad_mode.py:48(__init__)\n",
      "      144    0.041    0.000    0.041    0.000 {method 'pin_memory' of 'torch._C._TensorBase' objects}\n",
      "      827    0.039    0.000    0.640    0.001 lsr_tensor.py:21(init_params)\n",
      "15399/5133    0.039    0.000    0.348    0.000 collate.py:87(collate)\n",
      "    24636    0.038    0.000    0.115    0.000 module.py:1617(__setattr__)\n",
      "   170748    0.036    0.000    0.036    0.000 {built-in method torch.is_grad_enabled}\n",
      "    35792    0.036    0.000    0.135    0.000 container.py:290(__getitem__)\n",
      "     5275    0.035    0.000    0.708    0.000 dataloader.py:675(_next_data)\n",
      "    56275    0.035    0.000    0.618    0.000 _ops.py:497(__call__)\n",
      "    56276    0.032    0.000    0.047    0.000 typing.py:329(__hash__)\n",
      "        1    0.032    0.032    0.037    0.037 __init__.py:539(_raw_device_count_nvml)\n",
      "    56133    0.032    0.000    0.068    0.000 {built-in method builtins.all}\n",
      "    33052    0.031    0.000    0.560    0.000 {built-in method numpy.core._multiarray_umath.implement_array_function}\n",
      "    25500    0.031    0.000    0.076    0.000 optimizer.py:64(_default_to_fused_or_foreach)\n",
      "    56275    0.030    0.000    0.258    0.000 _ops.py:286(__call__)\n",
      "    13504    0.030    0.000    0.155    0.000 {built-in method builtins.sorted}\n",
      "    36073    0.030    0.000    0.030    0.000 {method 'format' of 'str' objects}\n",
      "    62314    0.030    0.000    0.030    0.000 {method 'size' of 'torch._C._TensorBase' objects}\n",
      "     1768    0.028    0.000    0.028    0.000 {built-in method torch.sign}\n",
      "    25500    0.028    0.000    0.036    0.000 _foreach_utils.py:24(<listcomp>)\n",
      "    25500    0.028    0.000    0.028    0.000 {built-in method torch._C._are_functorch_transforms_active}\n",
      "     5275    0.028    0.000    0.881    0.000 dataloader.py:628(__next__)\n",
      "     4328    0.025    0.000    0.030    0.000 module.py:437(__init__)\n",
      "     2550    0.025    0.000    0.037    0.000 optimizer.py:489(add_param_group)\n",
      "   180292    0.025    0.000    0.025    0.000 container.py:625(__len__)\n",
      "    31416    0.024    0.000    0.052    0.000 grad_mode.py:53(__enter__)\n",
      "    25500    0.024    0.000    0.566    0.000 base.py:5(tensor_to_vec)\n",
      "    51000    0.024    0.000    0.024    0.000 optimizer.py:72(<genexpr>)\n",
      "    33052    0.024    0.000    0.589    0.000 <__array_function__ internals>:2(prod)\n",
      "     5133    0.024    0.000    0.252    0.000 fetch.py:51(<listcomp>)\n",
      "   105060    0.023    0.000    0.038    0.000 _tensor.py:942(__hash__)\n",
      "     1020    0.023    0.000    0.023    0.000 {built-in method torch.kron}\n",
      "     9799    0.022    0.000    0.045    0.000 module.py:539(register_parameter)\n",
      "    31416    0.021    0.000    0.050    0.000 grad_mode.py:57(__exit__)\n",
      "    25500    0.020    0.000    0.030    0.000 _foreach_utils.py:27(<lambda>)\n",
      "   235803    0.020    0.000    0.020    0.000 {method 'append' of 'list' objects}\n",
      "    33052    0.020    0.000    0.020    0.000 fromnumeric.py:71(<dictcomp>)\n",
      "    31376    0.020    0.000    0.066    0.000 _contextlib.py:141(clone)\n",
      "     5512    0.020    0.000    2.006    0.000 lsr_tensor.py:81(forward)\n",
      "     4590    0.019    0.000    0.080    0.000 base.py:82(partial_unfold)\n",
      "    15300    0.019    0.000    0.053    0.000 module.py:2045(_named_members)\n",
      "33150/12750    0.019    0.000    0.021    0.000 module.py:2224(named_modules)\n",
      "     7599    0.019    0.000    0.019    0.000 {built-in method _make_subclass}\n",
      "      826    0.018    0.000    0.363    0.000 lsr_tensor.py:49(copy)\n",
      "      300    0.018    0.000    7.952    0.027 federated_algos.py:63(client_update_factors)\n",
      "   189691    0.017    0.000    0.017    0.000 _jit_internal.py:1102(is_scripting)\n",
      "    47495    0.017    0.000    0.031    0.000 {built-in method builtins.hasattr}\n",
      "     5100    0.016    0.000    0.469    0.000 lsr_tensor.py:114(bcd_core_forward)\n",
      "   122762    0.016    0.000    0.016    0.000 {method 'values' of 'collections.OrderedDict' objects}\n",
      "    73538    0.016    0.000    0.022    0.000 container.py:311(__len__)\n",
      "     2550    0.016    0.000    0.131    0.000 optimizer.py:169(__init__)\n",
      "    14524    0.016    0.000    0.022    0.000 container.py:628(__iter__)\n",
      "    54016    0.015    0.000    0.027    0.000 pytorch_backend.py:60(ndim)\n",
      "   105060    0.015    0.000    0.015    0.000 {built-in method builtins.id}\n",
      "      110    0.015    0.000    0.015    0.000 {built-in method torch._C._linalg.linalg_vector_norm}\n",
      "    56278    0.015    0.000    0.015    0.000 {built-in method builtins.hash}\n",
      "    21449    0.015    0.000    0.021    0.000 parameter.py:8(__instancecheck__)\n",
      "      830    0.015    0.000    0.015    0.000 {built-in method torch.zeros}\n",
      "   113832    0.014    0.000    0.014    0.000 {built-in method torch._C._set_grad_enabled}\n",
      "    25501    0.014    0.000    0.024    0.000 {built-in method builtins.any}\n",
      "    10266    0.013    0.000    0.254    0.000 collate.py:153(collate_tensor_fn)\n",
      "    43572    0.013    0.000    0.128    0.000 container.py:629(<genexpr>)\n",
      "    60098    0.013    0.000    0.013    0.000 {method 'dim' of 'torch._C._TensorBase' objects}\n",
      "     5326    0.013    0.000    0.014    0.000 sampler.py:241(__iter__)\n",
      "    31012    0.013    0.000    0.018    0.000 _VF.py:26(__getattr__)\n",
      "    31012    0.012    0.000    0.012    0.000 _reduction.py:7(get_enum)\n",
      "        1    0.012    0.012    3.839    3.839 federated_algos.py:144(BCD_federated_stepwise)\n",
      "    25500    0.012    0.000    0.012    0.000 {method 'numel' of 'torch._C._TensorBase' objects}\n",
      "     8740    0.012    0.000    0.119    0.000 container.py:614(__setitem__)\n",
      "     6082    0.012    0.000    0.024    0.000 _tensor.py:904(__len__)\n",
      "   107420    0.012    0.000    0.012    0.000 {built-in method _operator.index}\n",
      "     2550    0.011    0.000    0.011    0.000 {method 'detach' of 'torch._C._TensorBase' objects}\n",
      "     2550    0.011    0.000    0.011    0.000 {built-in method torch.unsqueeze}\n",
      "    51000    0.010    0.000    0.010    0.000 sgd.py:285(<genexpr>)\n",
      "     6944    0.010    0.000    0.010    0.000 {built-in method torch._C._log_api_usage_once}\n",
      "     3060    0.010    0.000    0.109    0.000 _kronecker.py:8(kronecker)\n",
      "    31692    0.010    0.000    0.010    0.000 {built-in method torch._C._has_torch_function_unary}\n",
      "    71600    0.010    0.000    0.013    0.000 collate.py:137(<genexpr>)\n",
      "     6082    0.010    0.000    0.010    0.000 {built-in method torch._C._get_tracing_state}\n",
      "     2550    0.009    0.000    0.140    0.000 sgd.py:11(__init__)\n",
      "    25500    0.009    0.000    0.009    0.000 __init__.py:98(_tensor_or_tensors_to_tuple)\n",
      "    25500    0.008    0.000    0.008    0.000 _foreach_utils.py:27(<listcomp>)\n",
      "    31012    0.008    0.000    0.008    0.000 {built-in method torch._C._has_torch_function_variadic}\n",
      "     5133    0.008    0.000    0.613    0.000 fetch.py:46(fetch)\n",
      "     8282    0.008    0.000    0.012    0.000 container.py:315(__iter__)\n",
      "    11121    0.008    0.000    0.015    0.000 {built-in method _abc._abc_instancecheck}\n",
      "    27008    0.007    0.000    0.007    0.000 {method 'pop' of 'list' objects}\n",
      "     5133    0.007    0.000    0.269    0.000 collate.py:142(<listcomp>)\n",
      "    56275    0.007    0.000    0.007    0.000 __init__.py:89(annotate)\n",
      "    10826    0.007    0.000    0.007    0.000 module.py:1618(remove_from)\n",
      "     8748    0.006    0.000    0.064    0.000 {built-in method builtins.setattr}\n",
      "     5348    0.006    0.000    0.099    0.000 container.py:639(append)\n",
      "    15300    0.006    0.000    0.059    0.000 module.py:2084(named_parameters)\n",
      "    31012    0.006    0.000    0.006    0.000 {built-in method torch._C._has_torch_function}\n",
      "    15311    0.006    0.000    0.065    0.000 module.py:2059(parameters)\n",
      "    35602    0.006    0.000    0.006    0.000 {method 'items' of 'dict' objects}\n",
      "        1    0.005    0.005    0.005    0.005 {built-in method _ctypes.dlopen}\n",
      "    33052    0.005    0.000    0.005    0.000 fromnumeric.py:2876(_prod_dispatcher)\n",
      "    27008    0.005    0.000    0.005    0.000 {method 'insert' of 'list' objects}\n",
      "     7599    0.005    0.000    0.023    0.000 parameter.py:30(__new__)\n",
      "     5133    0.005    0.000    0.352    0.000 collate.py:204(default_collate)\n",
      "      827    0.005    0.000    0.666    0.001 lsr_tensor.py:8(__init__)\n",
      "28376/28325    0.004    0.000    0.007    0.000 {built-in method builtins.iter}\n",
      "5259/5139    0.004    0.000    0.005    0.000 {built-in method _abc._abc_subclasscheck}\n",
      "     4590    0.004    0.000    0.004    0.000 base.py:113(<listcomp>)\n",
      "    25500    0.004    0.000    0.004    0.000 {method 'values' of 'dict' objects}\n",
      "    22950    0.004    0.000    0.006    0.000 {method 'add' of 'set' objects}\n",
      "     2674    0.004    0.000    0.030    0.000 container.py:580(__init__)\n",
      "      162    0.004    0.000    0.004    0.000 {built-in method torch.mean}\n",
      "    25500    0.004    0.000    0.004    0.000 optimizer.py:249(_optimizer_step_code)\n",
      "     2550    0.004    0.000    0.006    0.000 optimizer.py:291(_patch_step_function)\n",
      "    27008    0.003    0.000    0.003    0.000 n_mode_product.py:124(<lambda>)\n",
      "    11121    0.003    0.000    0.018    0.000 abc.py:96(__instancecheck__)\n",
      "        1    0.003    0.003    3.480    3.480 federated_algos.py:198(BCD_federated_all_factors)\n",
      "    10200    0.003    0.000    0.004    0.000 module.py:2113(<lambda>)\n",
      "      193    0.003    0.000    0.012    0.000 dataloader.py:567(__init__)\n",
      "     2550    0.003    0.000    0.042    0.000 base.py:150(partial_tensor_to_vec)\n",
      "     1000    0.003    0.000    0.056    0.000 federated_algos.py:254(<lambda>)\n",
      "      120    0.003    0.000    6.417    0.053 federated_algos.py:72(client_update_full)\n",
      "    21449    0.003    0.000    0.003    0.000 {function _ParameterMeta.__instancecheck__ at 0x7fa2b8997040}\n",
      "10459/10357    0.002    0.000    0.031    0.000 {built-in method builtins.next}\n",
      "      110    0.002    0.000    0.017    0.000 functional.py:1387(norm)\n",
      "    20400    0.002    0.000    0.002    0.000 {method 'setdefault' of 'dict' objects}\n",
      "        2    0.002    0.001    6.747    3.373 federated_algos.py:250(BCD_federated_full_iteration)\n",
      "     1654    0.002    0.000    0.006    0.000 module.py:585(add_module)\n",
      "       12    0.002    0.000    0.094    0.008 federated_algos.py:283(<listcomp>)\n",
      "      193    0.002    0.000    0.002    0.000 {method 'random_' of 'torch._C._TensorBase' objects}\n",
      "     5275    0.002    0.000    0.017    0.000 dataloader.py:622(_next_index)\n",
      "       10    0.002    0.000    0.078    0.008 federated_algos.py:183(<listcomp>)\n",
      "    20400    0.002    0.000    0.002    0.000 {method 'items' of 'collections.OrderedDict' objects}\n",
      "       10    0.002    0.000    0.078    0.008 federated_algos.py:235(<listcomp>)\n",
      "      193    0.002    0.000    0.002    0.000 {built-in method torch.empty}\n",
      "     1654    0.002    0.000    0.009    0.000 container.py:377(append)\n",
      "5259/5139    0.002    0.000    0.007    0.000 abc.py:100(__subclasscheck__)\n",
      "      500    0.001    0.000    0.004    0.000 dataset.py:295(__getitem__)\n",
      "     2040    0.001    0.000    0.009    0.000 _kronecker.py:43(<listcomp>)\n",
      "      500    0.001    0.000    0.028    0.000 federated_algos.py:201(<lambda>)\n",
      "      500    0.001    0.000    0.027    0.000 federated_algos.py:148(<lambda>)\n",
      "    10266    0.001    0.000    0.001    0.000 worker.py:89(get_worker_info)\n",
      "     5136    0.001    0.000    0.001    0.000 _collections_abc.py:302(__subclasshook__)\n",
      "      160    0.001    0.000    0.010    0.000 federated_algos.py:79(avg_aggregation)\n",
      "      193    0.001    0.000    0.014    0.000 dataloader.py:661(__init__)\n",
      "      193    0.001    0.000    0.001    0.000 {method 'item' of 'torch._C._TensorBase' objects}\n",
      "       66    0.001    0.000    0.002    0.000 dataloader.py:225(__init__)\n",
      "     1020    0.001    0.000    0.001    0.000 {method 'indices' of 'slice' objects}\n",
      "      827    0.001    0.000    0.006    0.000 container.py:276(__init__)\n",
      "       36    0.001    0.000    0.001    0.000 {built-in method builtins.sum}\n",
      "      193    0.001    0.000    0.001    0.000 dataloader.py:74(create_fetcher)\n",
      "        1    0.001    0.001    9.065    9.065 lsr_bcd_regression.py:137(BCD_avg_local)\n",
      "      193    0.001    0.000    0.002    0.000 dataloader.py:98(_get_distributed_settings)\n",
      "1320/1254    0.001    0.000    0.001    0.000 dataloader.py:418(__setattr__)\n",
      "   216/72    0.001    0.000    0.042    0.001 pin_memory.py:53(pin_memory)\n",
      "        4    0.000    0.000    0.027    0.007 federated_algos.py:89(get_client_dataloaders)\n",
      "     2550    0.000    0.000    0.000    0.000 {method 'isdisjoint' of 'set' objects}\n",
      "        6    0.000    0.000   23.664    3.944 federated_tests.py:37(run_method_trial)\n",
      "       48    0.000    0.000    0.003    0.000 federated_algos.py:275(<listcomp>)\n",
      "      193    0.000    0.000    0.001    0.000 sampler.py:75(__iter__)\n",
      "      193    0.000    0.000    0.014    0.000 dataloader.py:383(_get_iterator)\n",
      "      193    0.000    0.000    0.001    0.000 distributed_c10d.py:683(is_initialized)\n",
      "      198    0.000    0.000    0.000    0.000 typing.py:868(__new__)\n",
      "      193    0.000    0.000    0.014    0.000 dataloader.py:428(__iter__)\n",
      "      290    0.000    0.000    0.001    0.000 dataset.py:198(__len__)\n",
      "      193    0.000    0.000    0.000    0.000 distributed_c10d.py:403(WORLD)\n",
      "       76    0.000    0.000    0.000    0.000 os.py:670(__getitem__)\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method torch.cuda._get_device_properties}\n",
      "      193    0.000    0.000    0.000    0.000 __init__.py:7(is_available)\n",
      "        1    0.000    0.000    0.006    0.006 __init__.py:339(__init__)\n",
      "       72    0.000    0.000    0.041    0.001 pin_memory.py:70(<listcomp>)\n",
      "       75    0.000    0.000    0.001    0.000 os.py:766(getenv)\n",
      "       40    0.000    0.000    0.002    0.000 federated_algos.py:222(<listcomp>)\n",
      "      452    0.000    0.000    0.000    0.000 dataloader.py:443(_auto_collation)\n",
      "      193    0.000    0.000    0.000    0.000 fetch.py:8(__init__)\n",
      "       74    0.000    0.000    0.001    0.000 __init__.py:91(_nvml_based_avail)\n",
      "       75    0.000    0.000    0.001    0.000 _collections_abc.py:657(get)\n",
      "       74    0.000    0.000    0.001    0.000 __init__.py:94(is_available)\n",
      "       66    0.000    0.000    0.000    0.000 {built-in method torch.set_vital}\n",
      "       78    0.000    0.000    0.000    0.000 os.py:748(encode)\n",
      "      4/1    0.000    0.000    0.193    0.193 __init__.py:219(_lazy_init)\n",
      "      193    0.000    0.000    0.000    0.000 distributed_c10d.py:323(default_pg)\n",
      "        1    0.000    0.000   24.134   24.134 <string>:1(<module>)\n",
      "      140    0.000    0.000    0.001    0.000 dataset.py:300(__len__)\n",
      "        1    0.000    0.000   24.134   24.134 {built-in method builtins.exec}\n",
      "       66    0.000    0.000    0.000    0.000 sampler.py:226(__init__)\n",
      "      193    0.000    0.000    0.000    0.000 dataloader.py:447(_index_sampler)\n",
      "       75    0.000    0.000    0.000    0.000 __init__.py:87(_is_compiled)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._get_operation_overload}\n",
      "       12    0.000    0.000    0.000    0.000 federated_algos.py:279(<listcomp>)\n",
      "       74    0.000    0.000    0.000    0.000 {built-in method torch._C._cuda_getDeviceCount}\n",
      "      198    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x90b780}\n",
      "        1    0.000    0.000    0.038    0.038 __init__.py:128(_check_capability)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.compile}\n",
      "       66    0.000    0.000    0.000    0.000 dataloader.py:394(multiprocessing_context)\n",
      "        2    0.000    0.000    0.000    0.000 __init__.py:390(__getitem__)\n",
      "       66    0.000    0.000    0.000    0.000 dataloader.py:488(check_worker_number_rationality)\n",
      "        1    0.000    0.000   24.134   24.134 federated_tests.py:46(run_combined_trial)\n",
      "       66    0.000    0.000    0.000    0.000 sampler.py:72(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.__build_class__}\n",
      "       78    0.000    0.000    0.000    0.000 {method 'encode' of 'str' objects}\n",
      "        1    0.000    0.000    0.000    0.000 _ops.py:239(__init__)\n",
      "        3    0.000    0.000    0.000    0.000 __init__.py:385(get_device_properties)\n",
      "        2    0.000    0.000    0.000    0.000 __init__.py:383(__getattr__)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:154(_check_cubins)\n",
      "        1    0.000    0.000    0.037    0.037 __init__.py:616(_device_count_nvml)\n",
      "      2/1    0.000    0.000    0.000    0.000 typing.py:347(__getitem__)\n",
      "        2    0.000    0.000    0.000    0.000 __init__.py:368(get_device_capability)\n",
      "        2    0.000    0.000    0.000    0.000 __init__.py:653(get_arch_list)\n",
      "        1    0.000    0.000    0.000    0.000 _ops.py:447(__getattr__)\n",
      "        1    0.000    0.000    0.003    0.003 federated_tests.py:49(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 optimizer.py:262(profile_hook_step)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:491(_parse_visible_devices)\n",
      "        3    0.000    0.000    0.000    0.000 typing.py:120(_type_check)\n",
      "        1    0.000    0.000    0.037    0.037 __init__.py:645(device_count)\n",
      "        9    0.000    0.000    0.000    0.000 __init__.py:150(<genexpr>)\n",
      "        8    0.000    0.000    0.000    0.000 typing.py:762(__setattr__)\n",
      "        1    0.000    0.000    0.000    0.000 functools.py:34(update_wrapper)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.min}\n",
      "       19    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}\n",
      "        1    0.000    0.000    0.000    0.000 typing.py:659(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:353(get_device_name)\n",
      "        1    0.000    0.000    0.000    0.000 os.py:678(__setitem__)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._get_schema}\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:165(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 typing.py:219(_remove_dups_flatten)\n",
      "       39    0.000    0.000    0.000    0.000 _collections_abc.py:392(__subclasshook__)\n",
      "       12    0.000    0.000    0.000    0.000 {method 'startswith' of 'str' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method posix.putenv}\n",
      "        8    0.000    0.000    0.000    0.000 typing.py:646(_is_dunder)\n",
      "        1    0.000    0.000    0.000    0.000 typing.py:496(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:1017(_handle_fromlist)\n",
      "        1    0.000    0.000    0.000    0.000 _collections_abc.py:664(__contains__)\n",
      "        5    0.000    0.000    0.000    0.000 __init__.py:176(is_initialized)\n",
      "        1    0.000    0.000    0.000    0.000 functools.py:64(wraps)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.delattr}\n",
      "        1    0.000    0.000    0.000    0.000 lsr_bcd_regression.py:156(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._cuda_getCompiledVersion}\n",
      "        1    0.000    0.000    0.000    0.000 lsr_bcd_regression.py:157(<listcomp>)\n",
      "        3    0.000    0.000    0.000    0.000 typing.py:358(<genexpr>)\n",
      "        3    0.000    0.000    0.000    0.000 _utils.py:7(_get_device_index)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:61(get_calls)\n",
      "        3    0.000    0.000    0.000    0.000 typing.py:669(<genexpr>)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:169(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 typing.py:172(_collect_type_vars)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:367(_FuncPtr)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._cuda_isInBadFork}\n",
      "        2    0.000    0.000    0.000    0.000 typing.py:532(__hash__)\n",
      "        2    0.000    0.000    0.000    0.000 typing.py:1149(cast)\n",
      "        2    0.000    0.000    0.000    0.000 typing.py:524(__eq__)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method torch._C._cuda_getArchFlags}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method _ctypes.byref}\n",
      "        5    0.000    0.000    0.000    0.000 {method 'endswith' of 'str' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'update' of 'dict' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Comparison of federated algos\n",
    "shape, ranks, separation_rank = (64, 64), (8, 8), 2\n",
    "lsr_dot_params = (shape, ranks, separation_rank, torch.float32, torch.device('cuda'))\n",
    "\n",
    "loss_fn = f.mse_loss\n",
    "aggregator_fn = avg_aggregation\n",
    "\n",
    "iters = 10\n",
    "\n",
    "path_base = \"../data/synth_size_test\"\n",
    "\n",
    "def data_fn_by_size(sample_size, val_sample_size=500, clients=10):\n",
    "    synth_tensor = get_synth_tensor(shape, ranks, separation_rank)\n",
    "    synth_dataset, synth_val_dataset = synthesize_data(synth_tensor, sample_size, val_sample_size)\n",
    "    synth_client_datasets = federate_dataset(synth_dataset, clients)\n",
    "    return (synth_dataset, synth_val_dataset, synth_client_datasets)\n",
    "    \n",
    "data = data_fn_by_size(sample_size=100)\n",
    "\n",
    "methods = [BCD_avg_local, lsr_bcd_regression, BCD_federated_stepwise, BCD_federated_all_factors, BCD_federated_full_iteration, BCD_federated_full_iteration]\n",
    "names = ['local', 'centralized', 'step', 'factors_core', 'one_iter', 'five_iter']\n",
    "\n",
    "gen_hypers = {\"max_rounds\": 1, \"max_iter\": iters, \"batch_size\": None, \"lr\": 0.001, \"momentum\": 0.9, \"steps\": 10, \"threshold\": 0.0}\n",
    "iter_hypers = {\"max_rounds\": iters, \"max_iter\": 1, \"batch_size\": None, \"lr\": 0.001, \"momentum\": 0.9, \"steps\": 10, \"threshold\": 0.0}\n",
    "iter_5_hypers = {\"max_rounds\": iters // 5, \"max_iter\": 5, \"batch_size\": None, \"lr\": 0.001, \"momentum\": 0.9, \"steps\": 10, \"threshold\": 0.0}\n",
    "\n",
    "arg_list = [(gen_hypers, loss_fn, False), # local\n",
    "            (gen_hypers, loss_fn, False), # centralized\n",
    "            (gen_hypers, loss_fn, aggregator_fn, False), # one step\n",
    "            (gen_hypers, loss_fn, aggregator_fn, False), # factors core\n",
    "            (iter_hypers, loss_fn, aggregator_fn, False), # one iter\n",
    "            (iter_5_hypers, loss_fn, aggregator_fn, False)] # five iter\n",
    "\n",
    "cProfile.run(\"run_combined_trial(methods, lsr_dot_params, data, arg_list, False)\", sort='tottime')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
